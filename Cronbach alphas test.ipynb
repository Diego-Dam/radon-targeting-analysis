{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing scale reliability through Cronbach's alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "kg = pd.read_csv(\"05-12-2021_kontrollgruppe_df.csv\", index_col=0) \n",
    "ug = pd.read_csv(\"05-12-2021_untersuchungsgruppe_df.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Cronbach's Alpha function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1)Transform the dataframe input into a correlation matrix.\n",
    "2)Calculate N and r.\n",
    "3)Use the formula to calculate Cronbach’s Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cronbach_alpha(df):\n",
    "    # 1. Transform the df into a correlation matrix\n",
    "    df_corr = df.corr()\n",
    "    \n",
    "    # 2.1 Calculate N\n",
    "    # The number of variables equals the number of columns in the df\n",
    "    N = df.shape[1]\n",
    "    \n",
    "    # 2.2 Calculate R\n",
    "    # Loop through the columns and append every relevant correlation to an array calles \"r_s\".\n",
    "    # Then, calculate the mean of \"r_s\"\n",
    "    rs = np.array([])\n",
    "    for i, col in enumerate(df_corr.columns):\n",
    "        sum_ = df_corr[col][i+1:].values\n",
    "        rs = np.append(sum_, rs)\n",
    "    mean_r = np.mean(rs)\n",
    "    \n",
    "   # 3. Use the formula to calculate Cronbach's Alpha \n",
    "    cronbach_alpha = (N * mean_r) / (1 + (N - 1) * mean_r)\n",
    "    return cronbach_alpha,df_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbach's alpha for unsicherheit score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items\n",
    "unsicherheit_fragen = ['US01_01', 'US01_02', 'US01_03', 'US01_04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfs only with the items\n",
    "kg_unsicherheit = kg[kg.columns.intersection(unsicherheit_fragen)]\n",
    "ug_unsicherheit = ug[ug.columns.intersection(unsicherheit_fragen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the two dfs\n",
    "unsicherheit = kg_unsicherheit.append(ug_unsicherheit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keine angabe (no answer)\n",
    "unsicherheit_clean = unsicherheit.drop(unsicherheit[(unsicherheit.US01_01 == 'Keine Angabe') |\n",
    "                                                       (unsicherheit.US01_02 == 'Keine Angabe') |\n",
    "                                                       (unsicherheit.US01_03 == 'Keine Angabe') |\n",
    "                                                       (unsicherheit.US01_04 == 'Keine Angabe')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 207)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count losses after dropping keine angabe\n",
    "len(unsicherheit),len(unsicherheit_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-921a7bc45294>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unsicherheit_clean[column] = unsicherheit_clean[column].map({\"stimme nicht zu\" : 1, \"stimme eher nicht zu\" : 2, \"stimme eher zu\" : 3, \"stimme zu\" : 4})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in unsicherheit_clean.columns:\n",
    "    unsicherheit_clean[column] = unsicherheit_clean[column].map({\"stimme nicht zu\" : 1, \"stimme eher nicht zu\" : 2, \"stimme eher zu\" : 3, \"stimme zu\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8336474294213784,\n",
       "           US01_01   US01_02   US01_03   US01_04\n",
       " US01_01  1.000000  0.612461  0.484656  0.601702\n",
       " US01_02  0.612461  1.000000  0.536893  0.542868\n",
       " US01_03  0.484656  0.536893  1.000000  0.558106\n",
       " US01_04  0.601702  0.542868  0.558106  1.000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cronbach alpha formula\n",
    "cronbach_alpha(unsicherheit_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbach's alpha for risikowahrnehmung score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items\n",
    "risikowahrnehmung_fragen = ['RW03_01', 'RW03_02', 'RW03_03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfs only with the items\n",
    "kg_risikowahrnehmung = kg[kg.columns.intersection(risikowahrnehmung_fragen)]\n",
    "ug_risikowahrnehmung = ug[ug.columns.intersection(risikowahrnehmung_fragen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the two dfs\n",
    "risikowahrnehmung = kg_risikowahrnehmung.append(ug_risikowahrnehmung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keine angabe (no answer)\n",
    "risikowahrnehmung_clean = risikowahrnehmung.drop(risikowahrnehmung[(risikowahrnehmung.RW03_01 == 'Keine Angabe') |\n",
    "                                                       (risikowahrnehmung.RW03_02 == 'Keine Angabe') |\n",
    "                                                       (risikowahrnehmung.RW03_03 == 'Keine Angabe')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 235)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count losses\n",
    "len(risikowahrnehmung),len(risikowahrnehmung_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-71-5aa2afca4acb>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  risikowahrnehmung_clean[column] = risikowahrnehmung_clean[column].map({\"gering\" : 1, \"eher gering\" : 2, \"eher hoch\" : 3, \"hoch\" : 4})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in risikowahrnehmung_clean.columns:\n",
    "    risikowahrnehmung_clean[column] = risikowahrnehmung_clean[column].map({\"gering\" : 1, \"eher gering\" : 2, \"eher hoch\" : 3, \"hoch\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7264245961724761,\n",
       "           RW03_01   RW03_02   RW03_03\n",
       " RW03_01  1.000000  0.543083  0.385528\n",
       " RW03_02  0.543083  1.000000  0.479961\n",
       " RW03_03  0.385528  0.479961  1.000000)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cronbach alpha formula\n",
    "cronbach_alpha(risikowahrnehmung_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbach's alpha for handlungsbereitschaft score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items\n",
    "handlungsbereitschaft_fragen = ['H201_01',\n",
    "                                'H201_02',\n",
    "                                'H202_01',\n",
    "                                'H202_02',\n",
    "                                'H202_03']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfs only with the items\n",
    "kg_handlungsbereitschaft = kg[kg.columns.intersection(handlungsbereitschaft_fragen)]\n",
    "ug_handlungsbereitschaft = ug[ug.columns.intersection(handlungsbereitschaft_fragen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the two dfs\n",
    "handlungsbereitschaft = kg_handlungsbereitschaft.append(ug_handlungsbereitschaft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keine angabe (no answer)\n",
    "handlungsbereitschaft_clean = handlungsbereitschaft.drop(handlungsbereitschaft[(handlungsbereitschaft.H201_01 == 'Keine Angabe') |\n",
    "                                                       (handlungsbereitschaft.H201_02 == 'Keine Angabe') |\n",
    "                                                       (handlungsbereitschaft.H202_01 == 'Keine Angabe') |\n",
    "                                                       (handlungsbereitschaft.H202_02 == 'Keine Angabe') |\n",
    "                                                       (handlungsbereitschaft.H202_03 == 'Keine Angabe')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 187)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count losses\n",
    "len(handlungsbereitschaft),len(handlungsbereitschaft_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-78-4a8d207f5295>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  handlungsbereitschaft_clean[column] = handlungsbereitschaft_clean[column].map({\"nein\" : 1, \"eher nein\" : 2, \"eher ja\" : 3, \"ja\" : 4})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in handlungsbereitschaft_clean.columns:\n",
    "    handlungsbereitschaft_clean[column] = handlungsbereitschaft_clean[column].map({\"nein\" : 1, \"eher nein\" : 2, \"eher ja\" : 3, \"ja\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7870859677785208,\n",
       "           H201_01   H201_02   H202_01   H202_02   H202_03\n",
       " H201_01  1.000000  0.330456  0.686232  0.287270  0.096611\n",
       " H201_02  0.330456  1.000000  0.264339  0.755679  0.541256\n",
       " H202_01  0.686232  0.264339  1.000000  0.427079  0.210683\n",
       " H202_02  0.287270  0.755679  0.427079  1.000000  0.651108\n",
       " H202_03  0.096611  0.541256  0.210683  0.651108  1.000000)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cronbach alpha formula\n",
    "cronbach_alpha(handlungsbereitschaft_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbach's alpha for coping score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coping special case because of two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items\n",
    "coping_fragen = ['CL01_02',\n",
    "                  'CL01_04',\n",
    "                  'CL01_06',\n",
    "                  'CL01_01',\n",
    "                  'CL01_03',\n",
    "                  'CL01_05',\n",
    "                  'CA01_02',\n",
    "                  'CA01_04',\n",
    "                  'CA01_06',\n",
    "                  'CA01_01',\n",
    "                  'CA01_03',\n",
    "                  'CA01_05',\n",
    "                  'CS01_02',\n",
    "                  'CS01_04',\n",
    "                  'CS01_06',\n",
    "                  'CS01_01',\n",
    "                  'CS01_03',\n",
    "                  'CS01_05']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lüften_positive = ['CL01_02', 'CL01_04', 'CL01_06']\n",
    "lüften_negative = ['CL01_01', 'CL01_03', 'CL01_05']\n",
    "\n",
    "abdichten_positive = ['CA01_02', 'CA01_04', 'CA01_06']\n",
    "abdichten_negative = ['CA01_01', 'CA01_03', 'CA01_05']\n",
    "\n",
    "sanierung_positive = ['CS01_02', 'CS01_04', 'CS01_06']\n",
    "sanierung_negative = ['CS01_01', 'CS01_03', 'CS01_05']\n",
    "\n",
    "response_efficacy_positive = ['CL01_02', 'CA01_02', 'CS01_02']\n",
    "response_efficacy_negative = ['CL01_01', 'CA01_01', 'CS01_01']\n",
    "\n",
    "response_cost_positive = ['CL01_04', 'CA01_04', 'CS01_04']\n",
    "response_cost_negative = ['CL01_03', 'CA01_03', 'CS01_03']\n",
    "\n",
    "self_efficacy_positive = ['CL01_06', 'CA01_06', 'CS01_06']\n",
    "self_efficacy_negative = ['CL01_05', 'CA01_05', 'CS01_05']\n",
    "\n",
    "all_positive = lüften_positive + abdichten_positive + sanierung_positive\n",
    "all_negative = lüften_negative + abdichten_negative + sanierung_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfs only with the items\n",
    "kg_coping = kg[kg.columns.intersection(coping_fragen)]\n",
    "ug_coping = ug[ug.columns.intersection(coping_fragen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the two dfs\n",
    "coping = kg_coping.append(ug_coping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keine angabe (no answer)\n",
    "coping_clean = coping.drop(coping[(coping.CL01_02 == 'Keine Angabe') |\n",
    "                                                       (coping.CL01_04 == 'Keine Angabe') |\n",
    "                                                       (coping.CL01_06 == 'Keine Angabe') |\n",
    "                                                       (coping.CL01_01 == 'Keine Angabe') |\n",
    "                                                       (coping.CL01_03 == 'Keine Angabe') |\n",
    "                                                       (coping.CL01_05 == 'Keine Angabe') |\n",
    "                                                       (coping.CA01_02 == 'Keine Angabe') |\n",
    "                                                       (coping.CA01_04 == 'Keine Angabe') |\n",
    "                                                       (coping.CA01_06 == 'Keine Angabe') |\n",
    "                                                       (coping.CA01_01 == 'Keine Angabe') |                     \n",
    "                                                       (coping.CA01_03 == 'Keine Angabe') |\n",
    "                                                       (coping.CA01_05 == 'Keine Angabe') |\n",
    "                                                       (coping.CS01_02 == 'Keine Angabe') |\n",
    "                                                       (coping.CS01_06 == 'Keine Angabe') |                     \n",
    "                                                       (coping.CS01_01 == 'Keine Angabe') |\n",
    "                                                       (coping.CS01_03 == 'Keine Angabe') |\n",
    "                                                       (coping.CS01_05 == 'Keine Angabe') |  \n",
    "                                                       (coping.CS01_04 == 'Keine Angabe')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 97)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count losses\n",
    "len(coping),len(coping_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-b88177e672c1>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  coping_clean[column] = coping_clean[column].map({\"stimme nicht zu\" : 1, \"stimme eher nicht zu\" : 2, \"stimme eher zu\" : 3, \"stimme zu\" : 4})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in coping_clean[coping_clean.columns.intersection(all_positive)].columns:\n",
    "    coping_clean[column] = coping_clean[column].map({\"stimme nicht zu\" : 1, \"stimme eher nicht zu\" : 2, \"stimme eher zu\" : 3, \"stimme zu\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-88-1d1c42d658e7>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  coping_clean[column] = coping_clean[column].map({\"stimme nicht zu\" : 4, \"stimme eher nicht zu\" : 3, \"stimme eher zu\" : 2, \"stimme zu\" : 1})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in coping_clean[coping_clean.columns.intersection(all_negative)].columns:\n",
    "    coping_clean[column] = coping_clean[column].map({\"stimme nicht zu\" : 4, \"stimme eher nicht zu\" : 3, \"stimme eher zu\" : 2, \"stimme zu\" : 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.789171943165655,\n",
       "           CL01_01   CL01_02   CL01_03   CL01_04   CL01_05   CL01_06   CA01_01  \\\n",
       " CL01_01  1.000000  0.458167  0.072439  0.294987  0.499425  0.122879  0.286180   \n",
       " CL01_02  0.458167  1.000000  0.052732  0.575402  0.335192  0.336438  0.106099   \n",
       " CL01_03  0.072439  0.052732  1.000000  0.180678  0.277019  0.212325  0.059577   \n",
       " CL01_04  0.294987  0.575402  0.180678  1.000000  0.317645  0.376445  0.132369   \n",
       " CL01_05  0.499425  0.335192  0.277019  0.317645  1.000000  0.283310  0.328039   \n",
       " CL01_06  0.122879  0.336438  0.212325  0.376445  0.283310  1.000000 -0.066913   \n",
       " CA01_01  0.286180  0.106099  0.059577  0.132369  0.328039 -0.066913  1.000000   \n",
       " CA01_02  0.041441  0.204890  0.114305  0.294556  0.160941  0.068454  0.408715   \n",
       " CA01_03  0.060715  0.104455  0.183539  0.064937  0.184380 -0.047546  0.146961   \n",
       " CA01_04  0.062790  0.166229  0.255856  0.295210  0.199170  0.331791  0.071557   \n",
       " CA01_05  0.265352  0.304516  0.205822  0.200715  0.318355  0.110235  0.249719   \n",
       " CA01_06 -0.064268  0.007967  0.085870  0.218597 -0.009240  0.055394  0.180158   \n",
       " CS01_01  0.007777  0.212925 -0.054568  0.115871  0.049737  0.029466  0.130667   \n",
       " CS01_02  0.037773  0.124282  0.083161  0.218146  0.125849  0.018678  0.402304   \n",
       " CS01_03  0.092769 -0.043747  0.050256 -0.009309  0.067106  0.103900  0.224608   \n",
       " CS01_04  0.091509  0.010316 -0.075643  0.087876  0.044983  0.017745  0.206206   \n",
       " CS01_05  0.131940  0.178133  0.312774  0.146635  0.304764  0.075245  0.187697   \n",
       " CS01_06  0.109442  0.026790  0.099295 -0.012526  0.025077  0.116732  0.203456   \n",
       " \n",
       "           CA01_02   CA01_03   CA01_04   CA01_05   CA01_06   CS01_01   CS01_02  \\\n",
       " CL01_01  0.041441  0.060715  0.062790  0.265352 -0.064268  0.007777  0.037773   \n",
       " CL01_02  0.204890  0.104455  0.166229  0.304516  0.007967  0.212925  0.124282   \n",
       " CL01_03  0.114305  0.183539  0.255856  0.205822  0.085870 -0.054568  0.083161   \n",
       " CL01_04  0.294556  0.064937  0.295210  0.200715  0.218597  0.115871  0.218146   \n",
       " CL01_05  0.160941  0.184380  0.199170  0.318355 -0.009240  0.049737  0.125849   \n",
       " CL01_06  0.068454 -0.047546  0.331791  0.110235  0.055394  0.029466  0.018678   \n",
       " CA01_01  0.408715  0.146961  0.071557  0.249719  0.180158  0.130667  0.402304   \n",
       " CA01_02  1.000000 -0.064319  0.384435  0.127585  0.323219  0.286871  0.671596   \n",
       " CA01_03 -0.064319  1.000000 -0.140511  0.149526  0.089574  0.084747  0.129299   \n",
       " CA01_04  0.384435 -0.140511  1.000000  0.316408  0.324111  0.080020  0.309744   \n",
       " CA01_05  0.127585  0.149526  0.316408  1.000000  0.289538 -0.088612  0.148231   \n",
       " CA01_06  0.323219  0.089574  0.324111  0.289538  1.000000  0.088218  0.311125   \n",
       " CS01_01  0.286871  0.084747  0.080020 -0.088612  0.088218  1.000000  0.293341   \n",
       " CS01_02  0.671596  0.129299  0.309744  0.148231  0.311125  0.293341  1.000000   \n",
       " CS01_03  0.196424 -0.218653  0.261584  0.201923  0.125926  0.157246  0.169938   \n",
       " CS01_04  0.270301  0.018714  0.311113  0.327516  0.443427  0.182772  0.405699   \n",
       " CS01_05  0.251236  0.088987  0.340982  0.492105  0.255141  0.059177  0.170434   \n",
       " CS01_06  0.244986  0.040298  0.154135  0.175351  0.206916  0.077533  0.364807   \n",
       " \n",
       "           CS01_03   CS01_04   CS01_05   CS01_06  \n",
       " CL01_01  0.092769  0.091509  0.131940  0.109442  \n",
       " CL01_02 -0.043747  0.010316  0.178133  0.026790  \n",
       " CL01_03  0.050256 -0.075643  0.312774  0.099295  \n",
       " CL01_04 -0.009309  0.087876  0.146635 -0.012526  \n",
       " CL01_05  0.067106  0.044983  0.304764  0.025077  \n",
       " CL01_06  0.103900  0.017745  0.075245  0.116732  \n",
       " CA01_01  0.224608  0.206206  0.187697  0.203456  \n",
       " CA01_02  0.196424  0.270301  0.251236  0.244986  \n",
       " CA01_03 -0.218653  0.018714  0.088987  0.040298  \n",
       " CA01_04  0.261584  0.311113  0.340982  0.154135  \n",
       " CA01_05  0.201923  0.327516  0.492105  0.175351  \n",
       " CA01_06  0.125926  0.443427  0.255141  0.206916  \n",
       " CS01_01  0.157246  0.182772  0.059177  0.077533  \n",
       " CS01_02  0.169938  0.405699  0.170434  0.364807  \n",
       " CS01_03  1.000000  0.443589  0.164022  0.143100  \n",
       " CS01_04  0.443589  1.000000  0.141688  0.381983  \n",
       " CS01_05  0.164022  0.141688  1.000000  0.156100  \n",
       " CS01_06  0.143100  0.381983  0.156100  1.000000  )"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cronbach alpha formula\n",
    "cronbach_alpha(coping_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cronbach's alpha for informationsverständnis score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items\n",
    "informationsverständnis_fragen = ['IS01_01',\n",
    "                                    'IS01_02',\n",
    "                                    'IS01_03',\n",
    "                                    'IS01_04',\n",
    "                                    'IS01_05',\n",
    "                                    'IS01_06',\n",
    "                                    'IS01_07',\n",
    "                                    'IS01_08',\n",
    "                                    'IS01_09',\n",
    "                                    'IS01_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the items in the same direction\n",
    "informationsverständnis_fragen_same_direction = ['IS01_01',\n",
    "                                    'IS01_02',\n",
    "                                    'IS01_03',\n",
    "                                    'IS01_04',\n",
    "                                    'IS01_05',\n",
    "                                    'IS01_07',\n",
    "                                    'IS01_08',\n",
    "                                    'IS01_09',\n",
    "                                    'IS01_10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dfs only with the items\n",
    "kg_informationsverständnis = kg[kg.columns.intersection(informationsverständnis_fragen)]\n",
    "ug_informationsverständnis = ug[ug.columns.intersection(informationsverständnis_fragen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join the two dfs\n",
    "informationsverständnis = kg_informationsverständnis.append(ug_informationsverständnis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop keine angabe (no answer)\n",
    "informationsverständnis_clean = informationsverständnis.drop(informationsverständnis[(informationsverständnis.IS01_01 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_02 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_03 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_04 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_05 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_06 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_07 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_08 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_09 == 'Keine Angabe') |\n",
    "                                                       (informationsverständnis.IS01_10 == 'Keine Angabe')].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 274)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count losses\n",
    "len(informationsverständnis),len(informationsverständnis_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-0b43a2eddeb2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  informationsverständnis_clean[\"IS01_06\"] = informationsverständnis_clean[\"IS01_06\"].map({\"nein\" : 4, \"eher nein\" : 3, \"eher ja\" : 2, \"ja\" : 1,  \"Keine Angabe\": 0})\n"
     ]
    }
   ],
   "source": [
    "# item IS01_06 was coded in the opposite direction\n",
    "informationsverständnis_clean[\"IS01_06\"] = informationsverständnis_clean[\"IS01_06\"].map({\"nein\" : 4, \"eher nein\" : 3, \"eher ja\" : 2, \"ja\" : 1,  \"Keine Angabe\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-45-a28d203a74ce>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  informationsverständnis_clean[column] = informationsverständnis_clean[column].map({\"nein\" : 1, \"eher nein\" : 2, \"eher ja\" : 3, \"ja\" : 4})\n"
     ]
    }
   ],
   "source": [
    "# replace stimme zu (agree) nicht zu (disagree) values\n",
    "for column in informationsverständnis_clean[informationsverständnis_clean.columns.intersection(informationsverständnis_fragen_same_direction)]:\n",
    "    informationsverständnis_clean[column] = informationsverständnis_clean[column].map({\"nein\" : 1, \"eher nein\" : 2, \"eher ja\" : 3, \"ja\" : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS01_01</th>\n",
       "      <th>IS01_02</th>\n",
       "      <th>IS01_03</th>\n",
       "      <th>IS01_04</th>\n",
       "      <th>IS01_05</th>\n",
       "      <th>IS01_06</th>\n",
       "      <th>IS01_07</th>\n",
       "      <th>IS01_08</th>\n",
       "      <th>IS01_09</th>\n",
       "      <th>IS01_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IS01_01  IS01_02  IS01_03  IS01_04  IS01_05  IS01_06  IS01_07  IS01_08  \\\n",
       "0        3.0      3.0      NaN      NaN      NaN      2.0      NaN      NaN   \n",
       "1        4.0      4.0      4.0      4.0      4.0      4.0      4.0      4.0   \n",
       "2        4.0      4.0      3.0      3.0      4.0      2.0      NaN      3.0   \n",
       "3        3.0      4.0      3.0      4.0      4.0      2.0      4.0      4.0   \n",
       "4        3.0      3.0      3.0      3.0      3.0      2.0      3.0      3.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "187      3.0      NaN      NaN      NaN      NaN      3.0      NaN      NaN   \n",
       "188      4.0      4.0      4.0      4.0      4.0      1.0      3.0      4.0   \n",
       "189      4.0      4.0      4.0      4.0      4.0      2.0      3.0      3.0   \n",
       "191      3.0      NaN      3.0      NaN      2.0      2.0      2.0      2.0   \n",
       "192      4.0      4.0      3.0      3.0      3.0      1.0      3.0      3.0   \n",
       "\n",
       "     IS01_09  IS01_10  \n",
       "0        NaN      NaN  \n",
       "1        4.0      4.0  \n",
       "2        3.0      3.0  \n",
       "3        3.0      NaN  \n",
       "4        3.0      NaN  \n",
       "..       ...      ...  \n",
       "187      NaN      2.0  \n",
       "188      4.0      4.0  \n",
       "189      3.0      3.0  \n",
       "191      NaN      NaN  \n",
       "192      3.0      3.0  \n",
       "\n",
       "[274 rows x 10 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "informationsverständnis_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8808320234581464,\n",
       "           IS01_01   IS01_02   IS01_03   IS01_04   IS01_05   IS01_06   IS01_07  \\\n",
       " IS01_01  1.000000  0.602117  0.454578  0.570411  0.664572 -0.460366  0.503692   \n",
       " IS01_02  0.602117  1.000000  0.630843  0.630575  0.690186 -0.328181  0.520222   \n",
       " IS01_03  0.454578  0.630843  1.000000  0.708827  0.686146 -0.338016  0.504336   \n",
       " IS01_04  0.570411  0.630575  0.708827  1.000000  0.784543 -0.299055  0.506518   \n",
       " IS01_05  0.664572  0.690186  0.686146  0.784543  1.000000 -0.423152  0.560317   \n",
       " IS01_06 -0.460366 -0.328181 -0.338016 -0.299055 -0.423152  1.000000 -0.315276   \n",
       " IS01_07  0.503692  0.520222  0.504336  0.506518  0.560317 -0.315276  1.000000   \n",
       " IS01_08  0.595954  0.576391  0.597253  0.638654  0.715947 -0.434963  0.749104   \n",
       " IS01_09  0.639738  0.623552  0.644539  0.682680  0.727861 -0.450364  0.657527   \n",
       " IS01_10  0.482660  0.520766  0.561461  0.671522  0.653581 -0.396481  0.567096   \n",
       " \n",
       "           IS01_08   IS01_09   IS01_10  \n",
       " IS01_01  0.595954  0.639738  0.482660  \n",
       " IS01_02  0.576391  0.623552  0.520766  \n",
       " IS01_03  0.597253  0.644539  0.561461  \n",
       " IS01_04  0.638654  0.682680  0.671522  \n",
       " IS01_05  0.715947  0.727861  0.653581  \n",
       " IS01_06 -0.434963 -0.450364 -0.396481  \n",
       " IS01_07  0.749104  0.657527  0.567096  \n",
       " IS01_08  1.000000  0.809275  0.707659  \n",
       " IS01_09  0.809275  1.000000  0.730064  \n",
       " IS01_10  0.707659  0.730064  1.000000  )"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply cronbach alpha formula\n",
    "cronbach_alpha(informationsverständnis_clean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
